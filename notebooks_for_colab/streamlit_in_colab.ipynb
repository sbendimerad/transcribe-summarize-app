{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4TX26s7XAgC",
        "outputId": "a877f687-67b5-4906-9966-748c4985100b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install git+https://github.com/openai/whisper.git -q\n",
        "! pip install openai\n",
        "! pip install streamlit\n",
        "! pip install pyngrok\n",
        "! pip install pydub\n",
        "!apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Replace `openai.api_key =` with Your API Key**\n",
        "\n",
        "If you are using this notebook to interact with OpenAI's GPT models, make sure to replace instances of `openai.api_key =` with your actual OpenAI API key. Your API key should be enclosed in double or single quotes, like this:\n",
        "\n",
        "Before replacement:\n",
        "```python\n",
        "openai.api_key = \"your-own-api-key\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a Streamlit app script\n",
        "%%writefile app.py\n",
        "\n",
        "import openai\n",
        "import whisper\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import io\n",
        "import tempfile\n",
        "import pydub\n",
        "import urllib\n",
        "\n",
        "\n",
        "def transcribe_audio(audio_file):\n",
        "    \"\"\"\n",
        "    Transcribe audio from the provided file.\n",
        "\n",
        "    Args:\n",
        "        audio_file (str): Path to the audio file.\n",
        "\n",
        "    Returns:\n",
        "        str: Transcribed text from the audio.\n",
        "    \"\"\"\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio_file)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def convert_to_mp3(audio_file):\n",
        "    \"\"\"\n",
        "    Convert an audio file to MP3 format.\n",
        "\n",
        "    Args:\n",
        "        audio_file (io.BytesIO): Audio data in bytes.\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the converted MP3 file.\n",
        "    \"\"\"\n",
        "    audio = pydub.AudioSegment.from_file(audio_file)\n",
        "    mp3_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
        "    mp3_file.name = mp3_file.name.replace(\"\\\\\", \"/\")\n",
        "    audio.export(mp3_file.name, format=\"mp3\")\n",
        "    return mp3_file.name\n",
        "\n",
        "# Define your summarize_text_with_chatgpt function (modify as needed)\n",
        "def summarize_text_with_chatgpt(input_text, model=\"gpt-3.5-turbo\"):\n",
        "    \"\"\"\n",
        "    Summarize text using the ChatGPT model.\n",
        "\n",
        "    Args:\n",
        "        input_text (str): Text to be summarized.\n",
        "        model (str): OpenAI GPT model to use (default is \"gpt-3.5-turbo\").\n",
        "\n",
        "    Returns:\n",
        "        str: Summarized text.\n",
        "    \"\"\"\n",
        "\n",
        "    openai.api_key = \"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\"\n",
        "\n",
        "    # Create a clear and detailed prompt\n",
        "    prompt = f\"Summarize the following text as if it's a course: {input_text}\"\n",
        "\n",
        "    # Provide context and specify your requirements\n",
        "    prompt += (\n",
        "        \" This is a course, and the summary should include key concepts, main points, and relevant details. \"\n",
        "        \"Please ensure the summary is well-formatted and informative.\"\n",
        "    )\n",
        "\n",
        "    # Mention the inclusion of titles and subtitles\n",
        "    prompt += (\n",
        "        \" You can also include titles and subtitles as needed to structure the summary.\"\n",
        "    )\n",
        "\n",
        "    # Create a message for the model\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    # Make a call to ChatGPT for text summarization\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.7,  # Adjust the temperature to control randomness\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "\n",
        "def main():\n",
        "    st.title(\"Audio Transcription and Summarization App\")\n",
        "\n",
        "    # File upload\n",
        "    uploaded_file = st.file_uploader(\"Upload an audio file\", type=[\"mp3\", \"wav\"])\n",
        "\n",
        "    # Initialize variables\n",
        "    transcribed_text = \"\"\n",
        "    summarized_text = \"\"\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        st.audio(uploaded_file, format=\"audio/mp3\")\n",
        "\n",
        "        # Convert uploaded audio to MP3 format\n",
        "        mp3_file_path = convert_to_mp3(uploaded_file)\n",
        "\n",
        "        # Transcribe the MP3 audio\n",
        "        transcribed_text = transcribe_audio(mp3_file_path)\n",
        "        summarized_text = summarize_text_with_chatgpt(transcribed_text)\n",
        "\n",
        "    # Display results\n",
        "    st.write(summarized_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Code Explanation\n",
        "\n",
        "**Print External IP Address:**\n",
        "\n",
        "- Displays your local machine's external IP address. You'll copy this IP in the provided URL.\n",
        "\n",
        "**Install Localtunnel:**\n",
        "\n",
        "- Installs `localtunnel`, a tool for exposing local web servers to the internet.\n",
        "\n",
        "**Expose Streamlit App:**\n",
        "\n",
        "- Runs a Streamlit app in the background.\n",
        "- Uses `localtunnel` to share the app on the internet, accessible via a public URL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "\n",
        "# Install localtunnel\n",
        "!npm install -g localtunnel\n",
        "\n",
        "# Run the Streamlit app in the background\n",
        "!streamlit run app.py &> logs.txt &\n",
        "\n",
        "# Expose the Streamlit app on port 8501 using localtunnel\n",
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
