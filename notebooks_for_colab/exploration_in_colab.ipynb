{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kv8sdVe5QV8"
      },
      "source": [
        "# 1. Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "FqS1H6LU5XdH",
        "outputId": "42bb3b7e-3f2f-4d51-86b8-a74ea800cc25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# Mount Google Drive for data storage\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\\n# Install required packages\\n!pip install git+https://github.com/openai/whisper.git -q\\n!pip install openai\\n!apt-get install -y ffmpeg\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mount Google Drive for data storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!pip install openai\n",
        "!pip install urllib\n",
        "!pip install Audio\n",
        "!apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Replace `openai.api_key =` with Your API Key**\n",
        "\n",
        "If you are using this notebook to interact with OpenAI's GPT models, make sure to replace instances of `openai.api_key =` with your actual OpenAI API key. Your API key should be enclosed in double or single quotes, like this:\n",
        "\n",
        "Before replacement:\n",
        "```python\n",
        "openai.api_key = \"your-old-api-key\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFkLPlGg5Y0B"
      },
      "outputs": [],
      "source": [
        "# Import necessary packages\n",
        "import whisper\n",
        "import openai\n",
        "from IPython.display import Audio\n",
        "import io\n",
        "import time\n",
        "import numpy as np\n",
        "import urllib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4E5JC2_5d9E"
      },
      "source": [
        "# 2. Speech to text part using whisper\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf6wg-Yk7Oxp"
      },
      "source": [
        "**The transcribe function :** we use the model.transcribe function to transcribe the audio from the provided file (\"sample_audio.mp3\"). The transcribe function takes care of converting the audio into text, making it suitable for scenarios where you only need the textual representation of the spoken words.\n",
        "\n",
        "**The decode function :** we perform a more comprehensive audio processing pipeline, including creating a log-Mel spectrogram and decoding the audio using a pre-trained model. The decode function goes beyond transcription and provides additional information about the audio, making it suitable for tasks where understanding the structure and content of the audio is important.\n",
        "\n",
        "**For this tutorial we can use one of them and for more informations check the whisper documentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD4eD1_x5lRX"
      },
      "outputs": [],
      "source": [
        "# Function to transcribe audio from a file\n",
        "def transcribe_audio(file_path):\n",
        "    \"\"\"\n",
        "    Transcribe audio from the provided file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the audio file.\n",
        "\n",
        "    Returns:\n",
        "        str: Transcribed text from the audio.\n",
        "    \"\"\"\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(file_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def decode_audio(file_path):\n",
        "    \"\"\"\n",
        "    Decode audio from the provided file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the audio file.\n",
        "\n",
        "    Returns:\n",
        "        str: Transcribed text from the decoded audio.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(file_path)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # Create a log-Mel spectrogram and move to the same device as the model\n",
        "    base_model = whisper.load_model(\"base\")\n",
        "    mel_spectrogram = whisper.log_mel_spectrogram(audio).to(base_model.device)\n",
        "\n",
        "    # Decode the audio\n",
        "    options = whisper.DecodingOptions(without_timestamps=True)\n",
        "    result = whisper.decode(base_model, mel_spectrogram, options)\n",
        "    text_transcribed = result.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15oc_jpH5pus",
        "outputId": "db2582d7-05bd-425c-dbee-e46434a4aa38"
      },
      "outputs": [],
      "source": [
        "# Load an example audio file\n",
        "!wget -O audio.mp3 http://www.moviesoundclips.net/movies1/darkknightrises/darkness.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "uI7emh336jwE",
        "outputId": "84f50529-178e-4060-b2ac-d5c8a8c3c021"
      },
      "outputs": [],
      "source": [
        "# Display the audio\n",
        "Audio(\"audio.mp3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfzryEjx5u7t",
        "outputId": "dde2835e-dd46-4b20-bef3-1e9da285f444"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 59.6MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# Transcribe audio from the example file OR use the decode function\n",
        "text_transcribed = transcribe_audio(\"audio.mp3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuMdTUHD6udY"
      },
      "source": [
        "# 3. Summarize using chatgpt API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGvv9H4M6ztz"
      },
      "outputs": [],
      "source": [
        "# Set up the OpenAI API client\n",
        "openai.api_key = \"PUT YOUR API KEY\"  # Replace with your actual API key between the brackets\n",
        "\n",
        "# Define a prompt for text summarization\n",
        "prompt = f\"Summarize the following text {text_transcribed}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmy1dZNE5NQe"
      },
      "outputs": [],
      "source": [
        "# Create a message for the model\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "# Request a text summary from the OpenAI GPT-3.5-turbo model\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=0.7,  # Adjust the temperature to control randomness\n",
        ")\n",
        "\n",
        "# Get the summarized text\n",
        "text_summarized = response.choices[0].message[\"content\"]\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
