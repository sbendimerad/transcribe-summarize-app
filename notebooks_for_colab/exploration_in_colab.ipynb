{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kv8sdVe5QV8"
      },
      "source": [
        "# 1. Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "FqS1H6LU5XdH",
        "outputId": "42bb3b7e-3f2f-4d51-86b8-a74ea800cc25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Mes dossiers personnels/mes cours/whisper\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Install required packages\\n!pip install git+https://github.com/openai/whisper.git -q\\n!pip install openai\\n!pip install streamlit\\n!pip install pyngrok\\n!pip install pydub\\n!apt-get install -y ffmpeg'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mount Google Drive for data storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change directory to your project folder\n",
        "%cd /content/drive/MyDrive/Mes dossiers personnels/mes cours/whisper\n",
        "\n",
        "# Install required packages\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!pip install openai\n",
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install pydub\n",
        "!apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFkLPlGg5Y0B"
      },
      "outputs": [],
      "source": [
        "# Import necessary packages\n",
        "import whisper\n",
        "from IPython.display import Audio\n",
        "import openai\n",
        "import time\n",
        "import numpy as np\n",
        "import urllib\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4E5JC2_5d9E"
      },
      "source": [
        "# 2. Speech to text part using whisper\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf6wg-Yk7Oxp"
      },
      "source": [
        "**The transcribe function :** we use the model.transcribe function to transcribe the audio from the provided file (\"sample_audio.mp3\"). The transcribe function takes care of converting the audio into text, making it suitable for scenarios where you only need the textual representation of the spoken words.\n",
        "\n",
        "**The decode function :** we perform a more comprehensive audio processing pipeline, including creating a log-Mel spectrogram and decoding the audio using a pre-trained model. The decode function goes beyond transcription and provides additional information about the audio, making it suitable for tasks where understanding the structure and content of the audio is important.\n",
        "\n",
        "**For this tutorial we can use one of them and for more informations check the whisper documentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD4eD1_x5lRX"
      },
      "outputs": [],
      "source": [
        "# Function to transcribe audio from a file\n",
        "def transcribe_audio(file_path):\n",
        "    \"\"\"\n",
        "    Transcribe audio from the provided file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the audio file.\n",
        "\n",
        "    Returns:\n",
        "        str: Transcribed text from the audio.\n",
        "    \"\"\"\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(file_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def decode_audio(file_path):\n",
        "    \"\"\"\n",
        "    Decode audio from the provided file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the audio file.\n",
        "\n",
        "    Returns:\n",
        "        str: Transcribed text from the decoded audio.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # Create a log-Mel spectrogram and move to the same device as the model\n",
        "    mel_spectrogram = whisper.log_mel_spectrogram(audio).to(base_model.device)\n",
        "\n",
        "    # Decode the audio\n",
        "    options = whisper.DecodingOptions(without_timestamps=True)\n",
        "    result = whisper.decode(base_model, mel_spectrogram, options)\n",
        "    text_transcribed = result.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15oc_jpH5pus",
        "outputId": "db2582d7-05bd-425c-dbee-e46434a4aa38"
      },
      "outputs": [],
      "source": [
        "# Load an example audio file\n",
        "!wget -O audio.mp3 http://www.moviesoundclips.net/movies1/darkknightrises/darkness.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "uI7emh336jwE",
        "outputId": "84f50529-178e-4060-b2ac-d5c8a8c3c021"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Audio' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\sbendime\\Projects\\whisper\\Notebooks\\whisper_chatgpt_api_exploration_colab.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sbendime/Projects/whisper/Notebooks/whisper_chatgpt_api_exploration_colab.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Display the audio\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sbendime/Projects/whisper/Notebooks/whisper_chatgpt_api_exploration_colab.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Audio(\u001b[39m\"\u001b[39m\u001b[39maudio.mp3\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Audio' is not defined"
          ]
        }
      ],
      "source": [
        "# Display the audio\n",
        "Audio(\"audio.mp3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfzryEjx5u7t",
        "outputId": "dde2835e-dd46-4b20-bef3-1e9da285f444"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 59.6MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# Transcribe audio from the example file OR use the decode function\n",
        "text_transcribed = transcribe_audio(\"audio.mp3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuMdTUHD6udY"
      },
      "source": [
        "# 3. Summarize using chatgpt API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGvv9H4M6ztz"
      },
      "outputs": [],
      "source": [
        "# Set up the OpenAI API client\n",
        "openai.api_key = \"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\"  # Replace with your actual API key\n",
        "\n",
        "# Define a prompt for text summarization\n",
        "prompt = f\"Summarize the following text as if it's a course: {text_transcribed}\"\n",
        "\n",
        "# Specify requirements for the summary\n",
        "prompt += (\n",
        "    \" This is a course, and the summary should include key concepts, main points, and relevant details. \"\n",
        "    \"Please ensure the summary is well-formatted and informative.\"\n",
        "     \"You can also include titles and subtitles as needed to structure the summary.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmy1dZNE5NQe"
      },
      "outputs": [],
      "source": [
        "# Create a message for the model\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "# Request a text summary from the OpenAI GPT-3.5-turbo model\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=0.7,  # Adjust the temperature to control randomness\n",
        ")\n",
        "\n",
        "# Get the summarized text\n",
        "text_summarized = response.choices[0].message[\"content\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAPL8chE8ayQ",
        "outputId": "72e910a6-813e-48d8-dec1-d793073eb415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Course Title: Understanding the Power of Darkness: Embracing Challenges and Overcoming Adversity\n",
            "\n",
            "Subtitle: Unveiling the Transformative Journey from Dark to Light\n",
            "\n",
            "Introduction:\n",
            "The course explores the profound impact of darkness on personal growth and resilience. Participants will learn to shift their perspective on challenges, embracing the transformative power of adversity. Through a series of engaging lessons, they will understand the value of the dark and how it can shape their lives.\n",
            "\n",
            "Module 1: The Nature of Darkness\n",
            "- Key Concepts: Adopting darkness, birth in darkness, living by darkness\n",
            "- Main Points: Darkness as a metaphor for adversity, understanding its transformative potential\n",
            "- Relevant Details: Exploring personal experiences with darkness, recognizing the different forms darkness can take\n",
            "\n",
            "Module 2: The Journey Towards the Light\n",
            "- Key Concepts: Seeing the light, becoming a man, the insignificance of the light\n",
            "- Main Points: Overcoming darkness, personal growth, the significance of attaining the light\n",
            "- Relevant Details: Reflecting on personal milestones, understanding the impact of light on one's perceptions\n",
            "\n",
            "Module 3: Brighton: A Symbol of Illumination\n",
            "- Key Concepts: Brighton as a metaphorical representation of light\n",
            "- Main Points: Understanding the significance of Brighton, the transformation towards enlightenment\n",
            "- Relevant Details: Examining the role of Brighton in the narrator's journey, analyzing the impact of newfound lightness on personal development\n",
            "\n",
            "Conclusion:\n",
            "This course provides a unique perspective on embracing challenges and transforming adversity into personal growth. Participants will gain a deeper understanding of the power of darkness, its role in shaping character, and the journey towards enlightenment. By the end of the course, individuals will be equipped with the tools to navigate and thrive in the face of adversity, ultimately embracing the transformative power of darkness.\n"
          ]
        }
      ],
      "source": [
        "print(text_summarized)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
